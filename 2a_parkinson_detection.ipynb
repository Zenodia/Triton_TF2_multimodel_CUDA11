{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refering TF serving url https://www.tensorflow.org/tfx/tutorials/serving/rest_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 224, 224, 3), (72,), (42, 224, 224, 3), (42,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the path to the training and testing directories\n",
    "dataset_wave='./data/spiral/'\n",
    "trainingPath = dataset_wave+ \"training/\"\n",
    "testingPath = dataset_wave+\"testing/\"\n",
    "\n",
    "\n",
    "def get_data(data_path):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    # loop through each image path and fetch the features, then write to index per row \n",
    "    #for ext in ('*.gif', '*.png', '*.jpg','*.jpeg'):\n",
    "    label_paths=['healthy','parkinson']\n",
    "    for label_path in label_paths:\n",
    "        img_dir=data_path+label_path\n",
    "        img_files=os.listdir(img_dir)\n",
    "        if label_path=='healthy':\n",
    "            ls=[ Y.append(0) for i in range(len(img_files))]\n",
    "        else:\n",
    "            ls=[ Y.append(1) for i in range(len(img_files))]\n",
    "        for im_name in img_files:\n",
    "            img = Image.open(img_dir+'/'+im_name)\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((224, 224), Image.BILINEAR)\n",
    "            img = np.array(img)\n",
    "\n",
    "            img=img/255\n",
    "            X.append(img)\n",
    "                \n",
    "    Y=np.array(Y)\n",
    "    X=np.array(X)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "Xtrain, Ytrain=get_data(trainingPath)\n",
    "Xtest,Ytest=get_data(testingPath )\n",
    "\n",
    "Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare a feed-forward neural network focus on recall as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosntruct custom metrics for monitoring \n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    recall = c1 / c3\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosntruct the model and give input/output tensor names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hand_drawing (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 53, 53, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 4,749,281\n",
      "Trainable params: 4,749,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, Dense, Input, Flatten\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "input_tensor = {\n",
    "    \"hand_drawing\": Input(name=\"hand_drawing\", shape=(224,224,3), dtype=\"float32\")}\n",
    "print(type(input_tensor['hand_drawing']))\n",
    "def get_model(input_tensor):\n",
    "    inputs = input_tensor['hand_drawing']\n",
    "    # Step 1 - Convolution\n",
    "    x = Conv2D(32, (3, 3), input_shape = (224, 224,3), activation = 'relu', padding=\"same\")(inputs)\n",
    "\n",
    "    # Step 2 - Pooling\n",
    "    x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "    # Adding a second convolutional layer\n",
    "    x = Conv2D(32, (3, 3), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "    # Adding a second convolutional layer\n",
    "    x = Conv2D(32, (3, 3), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "\n",
    "    # Adding a second convolutional layer\n",
    "    x = Conv2D(32, (3, 3), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "    # Step 3 - Flattening\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Step 4 - Full connection\n",
    "    x = Dense(units = 1024, activation = 'relu')(x)\n",
    "    outputs = Dense(units = 1, activation = 'sigmoid', name='outputs',dtype=\"float32\")(x)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "m=get_model(input_tensor)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.5972\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66667, saving model to FC_spiral_parkinson.h5\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.6530 - accuracy: 0.5972 - val_loss: 0.6524 - val_accuracy: 0.6667\n",
      "Epoch 2/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.6528\n",
      "Epoch 00002: val_accuracy improved from 0.66667 to 0.78571, saving model to FC_spiral_parkinson.h5\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 0.6489 - accuracy: 0.6528 - val_loss: 0.6164 - val_accuracy: 0.7857\n",
      "Epoch 3/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.6667\n",
      "Epoch 00003: val_accuracy improved from 0.78571 to 0.83333, saving model to FC_spiral_parkinson.h5\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 0.6127 - accuracy: 0.6667 - val_loss: 0.5847 - val_accuracy: 0.8333\n",
      "Epoch 4/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.8056\n",
      "Epoch 00004: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.5601 - accuracy: 0.8056 - val_loss: 0.5545 - val_accuracy: 0.8333\n",
      "Epoch 5/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.7639\n",
      "Epoch 00005: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.5420 - accuracy: 0.7639 - val_loss: 0.5623 - val_accuracy: 0.7143\n",
      "Epoch 6/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7500\n",
      "Epoch 00006: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.5135 - accuracy: 0.7500 - val_loss: 0.4869 - val_accuracy: 0.8095\n",
      "Epoch 7/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8333\n",
      "Epoch 00007: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.4416 - accuracy: 0.8333 - val_loss: 0.4989 - val_accuracy: 0.7143\n",
      "Epoch 8/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.7083\n",
      "Epoch 00008: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.4944 - accuracy: 0.7083 - val_loss: 0.3983 - val_accuracy: 0.8333\n",
      "Epoch 9/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.8611\n",
      "Epoch 00009: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.4136 - accuracy: 0.8611 - val_loss: 0.5553 - val_accuracy: 0.7619\n",
      "Epoch 10/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.7917\n",
      "Epoch 00010: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.4284 - accuracy: 0.7917 - val_loss: 0.9934 - val_accuracy: 0.5000\n",
      "Epoch 11/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.6944\n",
      "Epoch 00011: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.5470 - accuracy: 0.6944 - val_loss: 0.5990 - val_accuracy: 0.7619\n",
      "Epoch 12/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8056\n",
      "Epoch 00012: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.4818 - accuracy: 0.8056 - val_loss: 0.6082 - val_accuracy: 0.8333\n",
      "Epoch 13/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.7500\n",
      "Epoch 00013: val_accuracy did not improve from 0.83333\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.4847 - accuracy: 0.7500 - val_loss: 0.5348 - val_accuracy: 0.7381\n",
      "Epoch 14/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8056\n",
      "Epoch 00014: val_accuracy improved from 0.83333 to 0.88095, saving model to FC_spiral_parkinson.h5\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 0.4451 - accuracy: 0.8056 - val_loss: 0.4298 - val_accuracy: 0.8810\n",
      "Epoch 15/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.9028\n",
      "Epoch 00015: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.3443 - accuracy: 0.9028 - val_loss: 0.4432 - val_accuracy: 0.7857\n",
      "Epoch 16/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9028\n",
      "Epoch 00016: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.3026 - accuracy: 0.9028 - val_loss: 0.4618 - val_accuracy: 0.7619\n",
      "Epoch 17/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8472\n",
      "Epoch 00017: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.3942 - accuracy: 0.8472 - val_loss: 0.5112 - val_accuracy: 0.7619\n",
      "Epoch 18/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8472\n",
      "Epoch 00018: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.3682 - accuracy: 0.8472 - val_loss: 0.4952 - val_accuracy: 0.7857\n",
      "Epoch 19/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.9444\n",
      "Epoch 00019: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 0.3329 - accuracy: 0.9444 - val_loss: 0.3695 - val_accuracy: 0.8571\n",
      "Epoch 20/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9167\n",
      "Epoch 00020: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.2252 - accuracy: 0.9167 - val_loss: 0.3956 - val_accuracy: 0.8571\n",
      "Epoch 21/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8750\n",
      "Epoch 00021: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.2981 - accuracy: 0.8750 - val_loss: 0.4185 - val_accuracy: 0.8571\n",
      "Epoch 22/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.8750\n",
      "Epoch 00022: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.2606 - accuracy: 0.8750 - val_loss: 0.4951 - val_accuracy: 0.7619\n",
      "Epoch 23/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9028\n",
      "Epoch 00023: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.2385 - accuracy: 0.9028 - val_loss: 0.4347 - val_accuracy: 0.8095\n",
      "Epoch 24/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.9167\n",
      "Epoch 00024: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.2624 - accuracy: 0.9167 - val_loss: 0.3642 - val_accuracy: 0.8333\n",
      "Epoch 25/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9722\n",
      "Epoch 00025: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1350 - accuracy: 0.9722 - val_loss: 0.3394 - val_accuracy: 0.8571\n",
      "Epoch 26/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9861\n",
      "Epoch 00026: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.1076 - accuracy: 0.9861 - val_loss: 0.3444 - val_accuracy: 0.8571\n",
      "Epoch 27/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.8611\n",
      "Epoch 00027: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.3095 - accuracy: 0.8611 - val_loss: 0.6313 - val_accuracy: 0.7857\n",
      "Epoch 28/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.9028\n",
      "Epoch 00028: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.2689 - accuracy: 0.9028 - val_loss: 0.4397 - val_accuracy: 0.8095\n",
      "Epoch 29/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9444\n",
      "Epoch 00029: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.1485 - accuracy: 0.9444 - val_loss: 0.3315 - val_accuracy: 0.8571\n",
      "Epoch 30/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9861\n",
      "Epoch 00030: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.1771 - accuracy: 0.9861 - val_loss: 0.3363 - val_accuracy: 0.8810\n",
      "Epoch 31/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9861\n",
      "Epoch 00031: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.1302 - accuracy: 0.9861 - val_loss: 0.3432 - val_accuracy: 0.8333\n",
      "Epoch 32/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.8571\n",
      "Epoch 33/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8333\n",
      "Epoch 34/35\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 0.88095\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.7857\n",
      "Epoch 00034: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04cc1f8c18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "epochs=35\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', \n",
    "                           min_delta=0.001, \n",
    "                           patience=20, \n",
    "                           mode='max', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('FC_spiral_parkinson.h5', \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max', \n",
    "                             period=1)\n",
    "\n",
    "m.fit(Xtrain,Ytrain, batch_size=24,validation_data=(Xtest,Ytest),\n",
    "                    callbacks=[early_stop,checkpoint], epochs=epochs, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.7857\n",
      "accuracy on the testing dataset is : 0.7857142686843872\n"
     ]
    }
   ],
   "source": [
    "output=loaded_model.evaluate(Xtest,Ytest)\n",
    "type(output)\n",
    "print(\"accuracy on the testing dataset is :\", output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "## save model \n",
    "tf.saved_model.save(m, \"model_ckpt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
